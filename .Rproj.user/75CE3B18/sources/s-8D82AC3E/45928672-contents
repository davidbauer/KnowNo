library(jsonlite)
library(lubridate)
library(ggplot2)
library(tidyverse)
library(dplyr)

rm(list = ls())

#set username for file imports from and exports to OneDrive
user <- "bauerd"
#user <- "marie-jose"
setwd(paste0('/Users/', user ,'/NZZ-Mediengruppe/NZZ\ Storytelling\ -\ Dokumente/Vorlagen/Rapid-Response-Scripts/bitcoin-crypto'))

# define the start date you want
# (you might need to run the script multiple times with different start dates, depending on the graphics you are updating)
start.date <- '2017-01-01' #format yyyy-mm-dd, earliest available date is 2010-07-18
end.date <- Sys.Date() #gives you the most recent data, can be replaced with specific date with format yyyy-mm-dd

#get the data
URL <- paste0('https://api.coindesk.com/v1/bpi/historical/close.json?start=',
              start.date,
              '&end=',
              end.date)

# compute and visualise daily data
df <- fromJSON(URL)
df <- df$bpi %>%
  unlist %>%
  tibble(date=names(.), bpi=.) %>%
  mutate(date=ymd(date))
tail(df)

ggplot(df) +
  geom_line(aes(x=date, y=bpi)) +
  ylab('US-$') + xlab('Zeit') +
  ggtitle('Tägliche Werte')

# compute and visualise volatility of daily data
# method 1: dplyr
df <- df %>%
   mutate(volat=(
     100*(bpi-lag(bpi))/lag(bpi))
     )
#save volatility in its own variable
volat <- df[,c(1,3)]

ggplot(volat) +
  geom_line(aes(x=date, y=volat)) +
  ylab('Volatilität') + xlab('Zeit') +
  ggtitle('Tägliche Werte')

# compute and visualise weekly data (median per week)
aggreg <- df %>%
  mutate(week=week(date),
         year=year(date)) %>%
  group_by(year, week) %>%
  summarise(median_value=median(bpi)) %>%
  ungroup()

dat <- df %>%
  mutate(week=week(date),
         year=year(date))

dat <- dat$date[!duplicated(dat[,c('week', 'year')])]

aggreg <- cbind(tibble(date=dat),aggreg) %>% as_tibble()

ggplot(aggreg) +
  geom_line(aes(x=date, y=median_value)) +
  ylab('US-$') + xlab('Zeit [here : rownumber]') +
  ggtitle('Wöchtentlicher Median')

# compute and visualise mixed data (the latest 30 days is daily, anything older weekly median)
weekly <- aggreg %>%
  filter(date < end.date-300) %>%
  select(date, value = median_value)

daily <- df %>%
  filter(date >= end.date-300) %>%
  select(date, value=bpi)

combined<-rbind(weekly, daily)

ggplot(combined) +
  geom_line(aes(x=date, y=value)) +
  ylab('US-$') + xlab('Zeit [here : rownumber]') +
  ggtitle('Wöchentlicher Median; für die letzten 300 Tage tägliche Werte')

#create a new folder with today's date
folderpath <- paste0('data-output/',Sys.Date(),'/')
dir.create(file.path(folderpath))

#save the files
write.csv(df, file=paste0(folderpath, 'btc_daily.csv'), row.names = F)
write.csv(aggreg, file=paste0(folderpath, 'btc_weeklymedian.csv'), row.names = F)
write.csv(volat, file=paste0(folderpath, 'btc_volatility.csv'), row.names = F)
write.csv(combined, file=paste0(folderpath, 'btc_mixed.csv'), row.names = F)

#open explainer with all the graphics to update
#for the market cap comparison, there's a separate R script
#the graphics on energy consumption are not script based. just grab the data from the source linked to in the graphic.
browseURL("https://www.nzz.ch/finanzen/bitcoin-kryptowaehrungen-im-ueberblick-ld.1336477")


# intraday data
# if you need intraday data for older dates, grab it as a csv from https://www.coindesk.com/price/
library(anytime)

# get the data
intra <- fromJSON('https://min-api.cryptocompare.com/data/histominute?fsym=BTC&tsym=USD&aggregate=5&e=CCCAGG')
intraday <- intra$Data %>%
  mutate(time=anytime(time))
intraday

write.csv(intraday, file=paste0(folderpath, 'btc_intraday.csv'), row.names = F)

